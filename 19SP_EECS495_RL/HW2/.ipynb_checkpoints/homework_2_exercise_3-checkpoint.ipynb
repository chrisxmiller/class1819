{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Exercise 3: </span>  Shortest path via Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src= 'images/shortest_path_both.png' width=\"100%\" height=\"100%\" alt=\"\"/>\n",
    "<figcaption>  <strong>Figure 1:</strong>   <em>  (left panel) A directed acyclic graph.  (right panel) The same graph with each step transition cost labeled on its corresponding edge. </em>  </figcaption> \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a [Python dictionary](https://www.tutorialspoint.com/python/python_dictionary.htm) representation of the graph above - along with transition costs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = { \n",
    "          'A': {'B': 3, 'C':  5},\n",
    "          'B' : {'C': 1, 'E': 2},\n",
    "          'C' : {'E': 4,'F': 4},\n",
    "          'D' : {'G': 3},\n",
    "          'E' : {'D': 2,'F': 2, 'G': 7},\n",
    "          'F' : {'G': 5},\n",
    "          'G' : []\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The first line in ``graph``\n",
    "\n",
    "`'A': {'B': 3, 'C':  5}`\n",
    "\n",
    "denotes the portion of the graph including starting at node **A** along with all other nodes it connects too via a directed edge stemming from **A** (as shown in the illustration above).  Here those two nodes are **B** and **C**, and each has a corresponding transition cost (moving from **A**) of 3 and 5 respectively.  Notice that the last line \n",
    "\n",
    "`'G' : []` \n",
    "\n",
    "states that node **G** connects to node via a directed edge where this edge stems from **G**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will use the Value Iteration algorithm - the first / fundamental Approximate Dynamic Programming algorithm described in the [course notes](https://www.dropbox.com/s/khu8pby8s8y0tn3/dynamic_programming_class_notes.pdf?dl=0) - to determine the shortest path starting from node **A** and ending at node **G** in the graph shown below (the same graph used in the previous exercise). \n",
    "\n",
    "In completing this exercise you should use the *dictionary* representation of the graph / cost structure above (or, in other words, your $f_{\\text{system}}$ and cost structure) provided above, as well as another dictionary for your $Q$ function.  Below is a $Q$ function initialized to all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = { \n",
    "      'A': {'B': 0, 'C': 0},\n",
    "      'B' : {'C': 0, 'E': 0},\n",
    "      'C' : {'E': 0,'F': 0},\n",
    "      'D' : {'G': 0},\n",
    "      'E' : {'D': 0,'F': 0, 'G': 0},\n",
    "      'F' : {'G': 0},\n",
    "      'G' : {'G': 0}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: you are not performing Q-Learning here, but nonetheless the function $Q$ must be maintained and updated in order to perform  Value Iteration *and* recover the optimal control law / shortest path after completion.  The general $t^{th}$ Value Iteration step (recursing *down* the set of fundamental DP equations)\n",
    "\n",
    "\\begin{equation}\n",
    "V\\left(s_{t+1}\\right) = \\underset{a_t}{\\text{minimize}}\\left[g\\left(s_t,a_t\\right) + V\\left(s_{t+1}\\right)\\right]\n",
    "\\end{equation}\n",
    "\n",
    "is written in terms of $Q$ as\n",
    "\n",
    "\\begin{equation}\n",
    "V\\left(s_{t+1}\\right) = \\underset{a_t}{\\text{minimize}}\\left[g\\left(s_t,a_t\\right) + \\underset{a_{t+1}}{\\text{minimize}}\\,Q\\left(s_{t+1},a_{t+1}\\right)\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note a few technical points about your final implementation:\n",
    "\n",
    "- During each step of an episode you should transition *randomly* from node-to-node.  Because you are dealing with such a small graph here this will allow you to explore the entire graph after just a few episodes.\n",
    "\n",
    "\n",
    "- Because this is such a small graph you should only need to run a maximum of $10$ episodes of Value Iteration in order for the values of $Q$ to converge to the optimal values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
