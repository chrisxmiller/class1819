{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Basic data manipulation commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: There is nothing to turn in for this exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this folder you will find the file `breast_cancer_original.txt` which contains a popular breast cancer dataset  consisting of $699$ data points.  You can find a general description of the contents of this file below (you may have to copy and paste this link into your browser for it to direct you properly)\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "\n",
    "There are several datasets listed under 'Data folder', the one we deal with here is called `breast-cancer-wisconsin.data` and [listed here](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data) (you can find out more about the specific entries of this dataset [here](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note in particular that \n",
    "\n",
    "- each **row** of this dataset contains information about a single patient\n",
    "\n",
    "- the **first column** contains the ID number of the patient\n",
    "\n",
    "- the **last column** contains the patient's diagnosis (2 = they have cancer, 4 = they do not), these are called *labels* in the jargon of machine learning\n",
    "\n",
    "- every column in-between the first and last contains information about the individual, these are called *input features* or just *features* in the jargon of machine learning (each column is itself a *feature*)\n",
    "\n",
    "- one column has several **missing entries**, denoted by the '?' character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this set of review exercises you will perform several basic data manipulation and transformation tasks on this dataset using the `numpy` and `pandas` (Python) libraries that come with your Anaconda installation.  If you are unfamiliar with thes libraries you will need to quickly get up to speed on their basic usage by reviewing an online tutorial or working with other students in the class.  **Use StackOverflow and Google to help yourself if you get stuck!**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example 1. </span> Basic data manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pandas` and `numpy` to\n",
    "\n",
    "- load in the dataset\n",
    "\n",
    "\n",
    "- delete the first column of the data (containing the patient ID numbers)\n",
    "\n",
    "\n",
    "- convert all entries to `float` values\n",
    "\n",
    "\n",
    "- find and replace any missing input feature value with the *mean of this feature across the entire set of patients*\n",
    "\n",
    "\n",
    "- replace the label values 2 and 4 in the last column of the dataset with -1 and +1 respectively\n",
    "\n",
    "\n",
    "\n",
    "- *transpose* the data so that each patient's transformed data lies along a column of the array, with their features contained in the first $9$ rows and corresponding label in the final row - your dataset array should be of size $\\left(10 \\times 699\\right)$ after transposition\n",
    "\n",
    "\n",
    "\n",
    "Once you have performed the required manipulations above *save* your transformed and transposed dataset as a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once complete the dataset is prepared for classification - a primary machine learning task.  We can denote this dataset algebraically as the set of input/output pairs $\\left\\{\\mathbf{x}_p,y_p\\right\\}_{p=1}^P$.  Note here $P = 699$, and the pair $\\left(\\mathbf{x}_p,y_p\\right)$ denotes the $p^{th}$ input / output pair where $\\mathbf{x}_p$ is a $N = 9$ dimensional set of input features for patient $p$ and $y_p$ is their corresponding label value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example 2. </span>  Standard normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Standard normalization* is a common feature transformation technique used in machine learning that consists of *mean-centering* and *scaling* each input features of a dataset by its standard deviation.  That is for $n=1,...,N$ we replace our input feature values as\n",
    "\n",
    "\\begin{equation}\n",
    "x_{p,n} \\longleftarrow \\frac{x_{p,n} - \\mu_n}{\\sigma_n}\n",
    "\\end{equation}\n",
    "\n",
    "where $x_{p,n}$ is the $n^{th}$ coordinate of point $\\mathbf{x}_p$ and $\\mu_n$ and $\\sigma_n$ are the mean and standard deviation of the $n^{th}$ dimension of the data, respectively, and are defined as \n",
    "\n",
    "\\begin{array}\n",
    "\\\n",
    "\\mu_n = \\frac{1}{P}\\sum_{p=1}^{P}x_{p,n} \\\\\n",
    "\\sigma_n = \\sqrt{\\frac{1}{P}\\sum_{p=1}^{P}\\left(x_{p,n} - \\mu_n \\right)^2}.\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform standard normalization on the input features of the resulting pre-processed breast cancer dataset from the Exercise above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in data manipulation library\n",
    "import pandas as pd\n",
    "from autograd import numpy as np\n",
    "\n",
    "# load in original dataset\n",
    "data = pd.read_csv('breast_cancer_original.txt',header = None)\n",
    "\n",
    "# drop user id column\n",
    "data.drop(0, axis=1, inplace=True)\n",
    "\n",
    "# replace '?' missing entries with np.nan values\n",
    "data.replace('?', np.nan,inplace = True)\n",
    "\n",
    "# replace arbitrary label values with pm 1\n",
    "data[10].replace([2,4],[-1,1],inplace = True)\n",
    "\n",
    "# convert all entries to floats\n",
    "data = data.astype(float)\n",
    "\n",
    "# convert dataframe to numpy array\n",
    "data = data.values\n",
    "\n",
    "# cut into input/output pairs\n",
    "x = data[:,:-1].T\n",
    "y = data[:,-1:].T"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
